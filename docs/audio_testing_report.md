## Audio Testing Report

Short audio samples (1 or 2 seconds) were taken on the Monterey bike path and at the top and bottom of the Emma McCrary Trail. This data was used to train and test various classification models.

### Data Preprocessing

Before feeding the data to any model, it must undergo some preprocessing. The steps are as follows:

1. An FFT of the data sample is calulculated.
1. Results are binned into 5000 buckets.

### Model training and testing

Four types of models were trained and tested. In each case, all of the data samples were split into two groups with a 65:35 ratio for training:testing. The training group was used to train the model while the testing group was used to test the trained model. The split was performed randomly, but in such a way that each group has a similar ratio of `bike`:`notbike` as the full data set's ratio. The same groups were used for all models.

The data presented below is the confusion matrix generated by testing each of the trained models with the testing group of data samples.

**K Nearest Neighbors Classifier** (k = 7)
|                |Bike Not Detected| Bike Detected |
|----------------|-----------------|---------------|
|Bike Not Passing|              22 |             9 |
|Bike Passing    |              11 |            38 |

**Random Forest Classifier**
|                |Bike Not Detected| Bike Detected |
|----------------|-----------------|---------------|
|Bike Not Passing|              20 |            11 |
|Bike Passing    |               5 |            44 |

**Linear Support Vector Classifier**
|                |Bike Not Detected| Bike Detected |
|----------------|-----------------|---------------|
|Bike Not Passing|              19 |            12 |
|Bike Passing    |              16 |            33 |

**Logistic Regression Classifier**
|                |Bike Not Detected| Bike Detected |
|----------------|-----------------|---------------|
|Bike Not Passing|              19 |            12 |
|Bike Passing    |              12 |            37 |

The Random Forest Classifier does the best with an accuracy of 80%.

Additional experimentation using only subsets of the data for training show that the audio models require more training data to do well. One model trained with data from one location will do worse at that location than one trained with data from all locations and then tested at that location simply because that one location does not have enough training data. Indeed, an RFC model trained and tested at only the EMT top location classified all 15 test samples as bikes even though 4 of them were not. This underscores the importance of collecting as much training data as possible in a variety of locations and conditions.

### Additional Preprocessing methods

These are each in the early stages of testing, but they could prove to be good methods. In addition to potentially giving better results, they also require much less calculation.  
**1. FFT of spectrogram**  
**2. FFT of MFCCs**

Both a spectrogram and an MFCC (Mel-frequency cepstral coefficients) are methods of interpreting sound data over time. A spectrogram is basically the result of calculating the fft of sequencial blocks of signal data. MFCC is similar but using non linear bin sizes and other tweaks to better highlight features of audio data as they are perceived by humans.

In this application, we do not want to keep the absolute time aspect of the data as that could differentiate some samples from each other in ways that are counterproductive. So for these preprocessing methods, we take an fft through time of each bin.

These methods both require more testing and tweaking, but so far, the best result comes from a Logistic Regression classifier using the `FFT of MFCCs` preprocessing method with an accuracy of 85%. Confusion matrix for this classifier:

**Logistic Regression Classifier for FFT of MFCCs**
|                |Bike Not Detected| Bike Detected |
|----------------|-----------------|---------------|
|Bike Not Passing|              26 |             5 |
|Bike Passing    |               7 |            42 |